{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "owned-clarity",
   "metadata": {},
   "source": [
    "# Label classifier (3dshapes): data collection\n",
    "\n",
    "## Task 2\n",
    "\n",
    "**Author**: Maleakhi A. Wijaya  \n",
    "**Description**: This notebook contains code used to collect experimentation data. We compare the performance of methods discussed in Rabanset et al. against our proposed CBSD method. The end-to-end task for task 2 is to predict the combination of scale and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "yellow-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load utilities functions\n",
    "%run ../../scripts/constants.py\n",
    "%run ../../scripts/3dshapes_utils.py\n",
    "%run ../../scripts/shift_applicator.py\n",
    "%run ../../scripts/shift_dimensionality_reductor.py\n",
    "%run ../../scripts/experiment_utils.py\n",
    "%run ../../scripts/shift_statistical_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "upset-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random seed\n",
    "SEED = 20\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-encounter",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "transparent-right",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 56000\n",
      "Testing samples: 14000\n"
     ]
    }
   ],
   "source": [
    "files_dir = \"../../data/3dshapes.h5\"\n",
    "# index 0 = image category\n",
    "X_train, X_test, y_train, y_test, c_train, c_test = train_test_split_3dshapes(files_dir, 70000, DatasetTask.Task2, \n",
    "                                                                               train_size=0.80, class_index=[3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "urban-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(np.concatenate([y_train, y_test])))\n",
    "concept_names = SHAPES3D_CONCEPT_NAMES\n",
    "concept_values = [len(np.unique(np.concatenate([c_train[:, i], c_test[:, i]]))) for i in range(c_train.shape[1])]\n",
    "\n",
    "# Split training into validation set as well \n",
    "X_train, X_valid = X_train[:40000], X_train[40000:]\n",
    "y_train, y_valid = y_train[:40000], y_train[40000:]\n",
    "c_train, c_valid = c_train[:40000], c_train[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "legal-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to appropriate shift input\n",
    "# It is noteworthy that for efficiency, we represent the images as only 2 dimension\n",
    "# when we preprocessing (number of instances/ batch size * flatten size).\n",
    "# When visualising back the image, we need to reshape it back to the original dimension\n",
    "ORIGINAL_SHAPE = X_test.shape[1:] # constant hold the image original shape\n",
    "X_test_flatten = deepcopy(X_test.reshape(X_test.shape[0], -1))\n",
    "X_train_flatten = deepcopy(X_train.reshape(X_train.shape[0], -1))\n",
    "X_valid_flatten = deepcopy(X_valid.reshape(X_valid.shape[0], -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-serial",
   "metadata": {},
   "source": [
    "## Dimensionality reduction\n",
    "\n",
    "We implemented various dimensionality reduction methods, amounting to:\n",
    "- End to end model (label classifiers/ BBSD)\n",
    "- Concept bottleneck model (CBSD)\n",
    "- Principal component analysis (PCA)\n",
    "- Sparse random projection (SRP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-membership",
   "metadata": {},
   "source": [
    "### End-to-end model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informative-negative",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "625/625 [==============================] - 11s 18ms/step - loss: 3.4466 - accuracy: 0.0462 - val_loss: 3.1825 - val_accuracy: 0.0845\n",
      "Epoch 2/200\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 2.6532 - accuracy: 0.1920 - val_loss: 1.3059 - val_accuracy: 0.7234\n",
      "Epoch 3/200\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 1.3000 - accuracy: 0.5482 - val_loss: 0.1587 - val_accuracy: 0.9854\n",
      "Epoch 4/200\n",
      "625/625 [==============================] - 9s 14ms/step - loss: 0.5038 - accuracy: 0.8230 - val_loss: 0.0222 - val_accuracy: 0.9994\n",
      "Epoch 5/200\n",
      "625/625 [==============================] - 9s 14ms/step - loss: 0.2375 - accuracy: 0.9202 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.1459 - accuracy: 0.9506 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.1023 - accuracy: 0.9656 - val_loss: 4.6279e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.0776 - accuracy: 0.9735 - val_loss: 2.3482e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.0615 - accuracy: 0.9798 - val_loss: 1.6740e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "625/625 [==============================] - 8s 14ms/step - loss: 0.0504 - accuracy: 0.9838 - val_loss: 9.0225e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.0442 - accuracy: 0.9851 - val_loss: 6.4211e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "625/625 [==============================] - 8s 14ms/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 4.9511e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.0327 - accuracy: 0.9893 - val_loss: 4.3335e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 3.1746e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.0264 - accuracy: 0.9916 - val_loss: 1.7069e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 1.2606e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 1.2513e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 1.0355e-05 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:From /home/maw219/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/maw219/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ../../models/end_to_end_3dshapes_task2/assets\n"
     ]
    }
   ],
   "source": [
    "path = \"../../models/end_to_end_3dshapes_task2\"\n",
    "# For training and saving\n",
    "histories, end_to_end_model = end_to_end_neural_network(n_classes, Dataset.SHAPES3D, \n",
    "                         X_train, y_train, X_valid, y_valid, path)\n",
    "\n",
    "# For loading\n",
    "end_to_end_model = tf.keras.models.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suspected-tongue",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       452\n",
      "           1       1.00      1.00      1.00       425\n",
      "           2       1.00      1.00      1.00       420\n",
      "           3       1.00      1.00      1.00       391\n",
      "           4       1.00      1.00      1.00       414\n",
      "           5       1.00      1.00      1.00       428\n",
      "           6       1.00      1.00      1.00       411\n",
      "           7       1.00      1.00      1.00       451\n",
      "           8       1.00      1.00      1.00       424\n",
      "           9       1.00      1.00      1.00       497\n",
      "          10       1.00      1.00      1.00       448\n",
      "          11       1.00      1.00      1.00       431\n",
      "          12       1.00      1.00      1.00       444\n",
      "          13       1.00      1.00      1.00       433\n",
      "          14       1.00      1.00      1.00       460\n",
      "          15       1.00      1.00      1.00       437\n",
      "          16       1.00      1.00      1.00       441\n",
      "          17       1.00      1.00      1.00       422\n",
      "          18       1.00      1.00      1.00       457\n",
      "          19       1.00      1.00      1.00       428\n",
      "          20       1.00      1.00      1.00       413\n",
      "          21       1.00      1.00      1.00       409\n",
      "          22       1.00      1.00      1.00       456\n",
      "          23       1.00      1.00      1.00       465\n",
      "          24       1.00      1.00      1.00       422\n",
      "          25       1.00      1.00      1.00       404\n",
      "          26       1.00      1.00      1.00       480\n",
      "          27       1.00      1.00      1.00       456\n",
      "          28       1.00      1.00      1.00       439\n",
      "          29       1.00      1.00      1.00       443\n",
      "          30       1.00      1.00      1.00       468\n",
      "          31       1.00      1.00      1.00       431\n",
      "\n",
      "    accuracy                           1.00     14000\n",
      "   macro avg       1.00      1.00      1.00     14000\n",
      "weighted avg       1.00      1.00      1.00     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "y_pred = end_to_end_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-planner",
   "metadata": {},
   "source": [
    "### Concept bottleneck model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-clinton",
   "metadata": {},
   "source": [
    "**Input to Concept**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "linear-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../models/multitask_3dshapes\"\n",
    "# For training and saving\n",
    "histories, mt_model = multitask_model(Dataset.SHAPES3D,\n",
    "                                            X_train, c_train,\n",
    "                                            X_valid, c_valid, path, concept_values)\n",
    "\n",
    "# For loading\n",
    "mt_model = tf.keras.models.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "intermediate-hydrogen",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Model: category ********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2426\n",
      "           1       1.00      1.00      1.00      2439\n",
      "           2       1.00      1.00      1.00      2429\n",
      "           3       1.00      1.00      1.00      2426\n",
      "           4       1.00      1.00      1.00      2430\n",
      "\n",
      "    accuracy                           1.00     12150\n",
      "   macro avg       1.00      1.00      1.00     12150\n",
      "weighted avg       1.00      1.00      1.00     12150\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "******************** Model: instance ********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      1263\n",
      "           1       0.90      0.86      0.88      1209\n",
      "           2       0.90      0.91      0.91      1167\n",
      "           3       0.89      0.87      0.88      1197\n",
      "           4       0.90      0.89      0.89      1210\n",
      "           5       0.92      0.87      0.89      1261\n",
      "           6       0.88      0.95      0.91      1179\n",
      "           7       0.93      0.86      0.89      1230\n",
      "           8       0.92      0.93      0.93      1199\n",
      "           9       0.89      0.94      0.91      1235\n",
      "\n",
      "    accuracy                           0.90     12150\n",
      "   macro avg       0.90      0.90      0.90     12150\n",
      "weighted avg       0.90      0.90      0.90     12150\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "******************** Model: elevation ********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.81      0.66      1331\n",
      "           1       0.38      0.39      0.38      1318\n",
      "           2       0.51      0.36      0.42      1360\n",
      "           3       0.52      0.44      0.48      1299\n",
      "           4       0.58      0.52      0.55      1379\n",
      "           5       0.55      0.49      0.52      1321\n",
      "           6       0.48      0.43      0.45      1378\n",
      "           7       0.39      0.32      0.35      1368\n",
      "           8       0.56      0.80      0.66      1396\n",
      "\n",
      "    accuracy                           0.51     12150\n",
      "   macro avg       0.50      0.51      0.50     12150\n",
      "weighted avg       0.50      0.51      0.50     12150\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "******************** Model: azimuth ********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       675\n",
      "           1       0.86      0.83      0.84       682\n",
      "           2       0.86      0.86      0.86       675\n",
      "           3       0.88      0.83      0.85       679\n",
      "           4       0.83      0.87      0.85       651\n",
      "           5       0.84      0.78      0.81       672\n",
      "           6       0.86      0.81      0.83       694\n",
      "           7       0.79      0.85      0.82       687\n",
      "           8       0.88      0.79      0.83       694\n",
      "           9       0.79      0.86      0.82       639\n",
      "          10       0.86      0.83      0.85       661\n",
      "          11       0.82      0.88      0.85       665\n",
      "          12       0.85      0.83      0.84       698\n",
      "          13       0.79      0.82      0.81       684\n",
      "          14       0.78      0.82      0.80       673\n",
      "          15       0.81      0.82      0.81       711\n",
      "          16       0.79      0.78      0.79       692\n",
      "          17       0.79      0.79      0.79       618\n",
      "\n",
      "    accuracy                           0.83     12150\n",
      "   macro avg       0.83      0.83      0.83     12150\n",
      "weighted avg       0.83      0.83      0.83     12150\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "******************** Model: lighting ********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76      1973\n",
      "           1       0.99      0.98      0.98      2013\n",
      "           2       1.00      1.00      1.00      2067\n",
      "           3       0.75      0.79      0.77      1955\n",
      "           4       1.00      1.00      1.00      2064\n",
      "           5       1.00      1.00      1.00      2078\n",
      "\n",
      "    accuracy                           0.92     12150\n",
      "   macro avg       0.92      0.92      0.92     12150\n",
      "weighted avg       0.92      0.92      0.92     12150\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "for i, pred in enumerate(mt_model.predict(X_test)):\n",
    "    print(\"*\"*20, f\"Model: {SHAPES3D_CONCEPT_NAMES[i]}\", \"*\"*20)\n",
    "    c_truth = c_test[:, i]\n",
    "    c_pred = np.argmax(pred, axis=1)\n",
    "    \n",
    "    print(classification_report(c_truth, c_pred))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-observer",
   "metadata": {},
   "source": [
    "**Concept to Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "referenced-cooperative",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and train model. For simplicity, we used logistic regression\n",
    "# although can be substituted using other model.\n",
    "com = LogisticRegression()\n",
    "com.fit(c_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "specialized-complement",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       372\n",
      "           1       0.75      0.95      0.84       327\n",
      "           2       0.96      0.79      0.87       499\n",
      "           3       0.80      0.89      0.84       345\n",
      "           4       0.84      0.82      0.83       414\n",
      "           5       1.00      0.94      0.97       454\n",
      "           6       0.82      0.89      0.85       364\n",
      "           7       0.77      0.90      0.83       356\n",
      "           8       0.94      0.97      0.96       433\n",
      "           9       1.00      1.00      1.00       394\n",
      "          10       1.00      1.00      1.00       390\n",
      "          11       1.00      1.00      1.00       392\n",
      "          12       0.94      0.84      0.89       449\n",
      "          13       0.98      1.00      0.99       383\n",
      "          14       0.88      0.77      0.83       455\n",
      "          15       0.99      0.99      0.99       391\n",
      "          16       0.97      0.95      0.96       443\n",
      "          17       1.00      1.00      1.00       409\n",
      "          18       1.00      1.00      1.00       391\n",
      "          19       1.00      0.99      1.00       392\n",
      "          20       0.99      1.00      0.99       412\n",
      "          21       0.89      0.88      0.88       382\n",
      "          22       0.99      0.99      0.99       433\n",
      "          23       0.95      0.96      0.96       409\n",
      "          24       0.99      1.00      0.99       388\n",
      "          25       1.00      0.99      0.99       403\n",
      "          26       1.00      1.00      1.00       397\n",
      "          27       1.00      0.99      0.99       413\n",
      "          28       1.00      0.94      0.97       424\n",
      "          29       1.00      1.00      1.00       436\n",
      "\n",
      "    accuracy                           0.95     12150\n",
      "   macro avg       0.95      0.95      0.95     12150\n",
      "weighted avg       0.95      0.95      0.95     12150\n",
      "\n",
      "[[370   1   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1 311  15   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 105 394   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 306  39   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0  76 338   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  27 427   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 13   0   0   0   0   0 325   0   0   0   0   0  26   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  3   0   0   0   0   0   0 322  25   0   0   0   0   5   1   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  11 422   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 394   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 390   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 392   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  71   0   0   0   0   0 378   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 383   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  86   0   0   0   0   0   0 352   0   0   0\n",
      "    0   0   0  17   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 387   0   0\n",
      "    0   0   0   0   4   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 423   0\n",
      "    0   0   0   0   0  20   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 409\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  391   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0\n",
      "    0 390   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 411   0   0   0   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45   0   0   0\n",
      "    0   0   0 337   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   0\n",
      "    0   0   0   0 430   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  15   0\n",
      "    0   0   0   0   0 394   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0 388   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    1   0   0   0   0   0   5 397   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0 397   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   5   0   0   0   0   0   0 408   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0  26   0   0   0   0   0   0 398   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0 436]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = com.predict(c_test)\n",
    "print(classification_report(y_test_pred, y_test))\n",
    "print(confusion_matrix(y_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-liechtenstein",
   "metadata": {},
   "source": [
    "### Principal component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "nasty-extreme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of components to explain 80% of variance is 2.\n"
     ]
    }
   ],
   "source": [
    "pca, n_components = principal_components_analysis(X_train_flatten)\n",
    "print(f\"The number of components to explain 80% of variance is {n_components}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-accent",
   "metadata": {},
   "source": [
    "### Sparse random projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "direct-attack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of components to explain 80% of variance is 2.\n"
     ]
    }
   ],
   "source": [
    "srp, n_components = sparse_random_projection(X_train_flatten)\n",
    "print(f\"The number of components to explain 80% of variance is {n_components}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-angle",
   "metadata": {},
   "source": [
    "## Data collection\n",
    "\n",
    "This section performs various experiments to collect data. We consider various dimensionality reduced methods discussed in the paper and thesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-apple",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "massive-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = DimensionalityReductor.PCA\n",
    "model = pca\n",
    "method_str = \"PCA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-stevens",
   "metadata": {},
   "source": [
    "#### Knockout shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "identified-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_type = ShiftType.Knockout\n",
    "shift_type_params = {\"cl\": MAJORITY}\n",
    "shift_str = \"ko_task2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "needed-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_result = main_experiment(model, method, X_valid, y_valid,\n",
    "                             c_valid, X_test_flatten, y_test, c_test,\n",
    "                             shift_type, ORIGINAL_SHAPE, n_classes,\n",
    "                             concept_names, concept_values, \n",
    "                             shift_type_params, n_exp=50, n_std=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "recovered-purple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save file\n",
    "save_result(shift_str, method_str, dict_result, True, \"3dshapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-steel",
   "metadata": {},
   "source": [
    "### SRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "nasty-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = DimensionalityReductor.SRP\n",
    "model = srp\n",
    "method_str = \"SRP\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-cross",
   "metadata": {},
   "source": [
    "#### Knockout shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chicken-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_type = ShiftType.Knockout\n",
    "shift_type_params = {\"cl\": MAJORITY}\n",
    "shift_str = \"ko_task2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "native-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_result = main_experiment(model, method, X_valid, y_valid,\n",
    "                             c_valid, X_test_flatten, y_test, c_test,\n",
    "                             shift_type, ORIGINAL_SHAPE, n_classes,\n",
    "                             concept_names, concept_values, \n",
    "                             shift_type_params, n_exp=50, n_std=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "based-dance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save file\n",
    "save_result(shift_str, method_str, dict_result, True, \"3dshapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-walker",
   "metadata": {},
   "source": [
    "### BBSDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "approximate-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = DimensionalityReductor.BBSDs\n",
    "model = end_to_end_model\n",
    "method_str = \"BBSDs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-nothing",
   "metadata": {},
   "source": [
    "#### Knockout shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "collective-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_type = ShiftType.Knockout\n",
    "shift_type_params = {\"cl\": MAJORITY}\n",
    "shift_str = \"ko_task2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "surface-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_result = main_experiment(model, method, X_valid, y_valid,\n",
    "                             c_valid, X_test_flatten, y_test, c_test,\n",
    "                             shift_type, ORIGINAL_SHAPE, n_classes,\n",
    "                             concept_names, concept_values, \n",
    "                             shift_type_params, n_exp=50, n_std=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "referenced-sleeve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save file\n",
    "save_result(shift_str, method_str, dict_result, True, \"3dshapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-dietary",
   "metadata": {},
   "source": [
    "#### Concept shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_type = ShiftType.Concept\n",
    "\n",
    "list_shift_str = [\n",
    "    \"floor_task2\",\n",
    "    \"wall_task2\",\n",
    "    \"object_scale_task2\",\n",
    "]\n",
    "\n",
    "list_shift_type_params = [\n",
    "    {\"cl\": MAJORITY, \"concept_idx\": 0}, # scale is index 2 in the concept names\n",
    "    {\"cl\": MAJORITY, \"concept_idx\": 1},\n",
    "    [{\"cl\": MAJORITY, \"concept_idx\": 2}, {\"cl\": MAJORITY, \"concept_idx\": 3}],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "for shift_str, shift_type_params in tqdm(zip(list_shift_str, list_shift_type_params)):\n",
    "    dict_result = main_experiment(model, method, X_valid, y_valid,\n",
    "                             c_valid, X_test_flatten, y_test, c_test,\n",
    "                             shift_type, ORIGINAL_SHAPE, n_classes,\n",
    "                             concept_names, concept_values, \n",
    "                             shift_type_params, n_exp=50, n_std=2)\n",
    "    \n",
    "    # Save\n",
    "    save_result(shift_str, method_str, dict_result, True, \"3dshapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-diameter",
   "metadata": {},
   "source": [
    "#### Image shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shift = [\n",
    "    ShiftType.Rotation,\n",
    "    ShiftType.Shear,\n",
    "    ShiftType.Flip,\n",
    "    ShiftType.All\n",
    "]\n",
    "\n",
    "list_shift_str = [\n",
    "    \"rotation_task2\",\n",
    "    \"shear_task2\",\n",
    "    \"flip_task2\",\n",
    "    \"all_task2\"\n",
    "]\n",
    "\n",
    "shift_type_param = {\"orig_dims\": ORIGINAL_SHAPE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "for shift_str, shift_type in tqdm(zip(list_shift_str, list_shift)):\n",
    "    dict_result = main_experiment(model, method, X_valid, y_valid,\n",
    "                             c_valid, X_test_flatten, y_test, c_test,\n",
    "                             shift_type, ORIGINAL_SHAPE, n_classes,\n",
    "                             concept_names, concept_values, \n",
    "                             shift_type_param, n_exp=50, n_std=2)\n",
    "    \n",
    "    # Save\n",
    "    save_result(shift_str, method_str, dict_result, True, \"3dshapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-smoke",
   "metadata": {},
   "source": [
    "#### Gaussian shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_type = ShiftType.Gaussian\n",
    "shift_type_params = None\n",
    "shift_str = \"gaussian_task2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_result = main_experiment(model, method, X_valid, y_valid,\n",
    "                             c_valid, X_test_flatten, y_test, c_test,\n",
    "                             shift_type, ORIGINAL_SHAPE, n_classes,\n",
    "                             concept_names, concept_values, \n",
    "                             shift_type_params, n_exp=50, n_std=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file\n",
    "save_result(shift_str, method_str, dict_result, True, \"3dshapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-gambling",
   "metadata": {},
   "source": [
    "### BBSDh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "biblical-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = DimensionalityReductor.BBSDh\n",
    "model = end_to_end_model\n",
    "method_str = \"BBSDh\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-policy",
   "metadata": {},
   "source": [
    "#### Knockout shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "derived-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_type = ShiftType.Knockout\n",
    "shift_type_params = {\"cl\": MAJORITY}\n",
    "shift_str = \"ko_task2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "matched-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_result = main_experiment(model, method, X_valid, y_valid,\n",
    "                             c_valid, X_test_flatten, y_test, c_test,\n",
    "                             shift_type, ORIGINAL_SHAPE, n_classes,\n",
    "                             concept_names, concept_values, \n",
    "                             shift_type_params, n_exp=50, n_std=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "emerging-cycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save file\n",
    "save_result(shift_str, method_str, dict_result, True, \"3dshapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-commitment",
   "metadata": {},
   "source": [
    "#### Concept shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_type = ShiftType.Concept\n",
    "\n",
    "list_shift_str = [\n",
    "    \"floor_task2\",\n",
    "    \"wall_task2\",\n",
    "    \"object_scale_task2\",\n",
    "]\n",
    "\n",
    "list_shift_type_params = [\n",
    "    {\"cl\": MAJORITY, \"concept_idx\": 0}, # scale is index 2 in the concept names\n",
    "    {\"cl\": MAJORITY, \"concept_idx\": 1},\n",
    "    [{\"cl\": MAJORITY, \"concept_idx\": 2}, {\"cl\": MAJORITY, \"concept_idx\": 3}],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "for shift_str, shift_type_params in tqdm(zip(list_shift_str, list_shift_type_params)):\n",
    "    dict_result = main_experiment(model, method, X_valid, y_valid,\n",
    "                             c_valid, X_test_flatten, y_test, c_test,\n",
    "                             shift_type, ORIGINAL_SHAPE, n_classes,\n",
    "                             concept_names, concept_values, \n",
    "                             shift_type_params, n_exp=50, n_std=2)\n",
    "    \n",
    "    # Save\n",
    "    save_result(shift_str, method_str, dict_result, True, \"3dshapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-thread",
   "metadata": {},
   "source": [
    "#### Image shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shift = [\n",
    "    ShiftType.Rotation,\n",
    "    ShiftType.Shear,\n",
    "    ShiftType.Flip,\n",
    "    ShiftType.All\n",
    "]\n",
    "\n",
    "list_shift_str = [\n",
    "    \"rotation_task2\",\n",
    "    \"shear_task2\",\n",
    "    \"flip_task2\",\n",
    "    \"all_task2\"\n",
    "]\n",
    "\n",
    "shift_type_param = {\"orig_dims\": ORIGINAL_SHAPE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "for shift_str, shift_type in tqdm(zip(list_shift_str, list_shift)):\n",
    "    dict_result = main_experiment(model, method, X_valid, y_valid,\n",
    "                             c_valid, X_test_flatten, y_test, c_test,\n",
    "                             shift_type, ORIGINAL_SHAPE, n_classes,\n",
    "                             concept_names, concept_values, \n",
    "                             shift_type_param, n_exp=50, n_std=2)\n",
    "    \n",
    "    # Save\n",
    "    save_result(shift_str, method_str, dict_result, True, \"3dshapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-notion",
   "metadata": {},
   "source": [
    "#### Gaussian shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_type = ShiftType.Gaussian\n",
    "shift_type_params = None\n",
    "shift_str = \"gaussian_task2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_result = main_experiment(model, method, X_valid, y_valid,\n",
    "                             c_valid, X_test_flatten, y_test, c_test,\n",
    "                             shift_type, ORIGINAL_SHAPE, n_classes,\n",
    "                             concept_names, concept_values, \n",
    "                             shift_type_params, n_exp=50, n_std=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file\n",
    "save_result(shift_str, method_str, dict_result, True, \"3dshapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-halloween",
   "metadata": {},
   "source": [
    "### CBSDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "higher-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = DimensionalityReductor.CBSDs\n",
    "model = mt_model\n",
    "method_str = \"CBSDs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-blade",
   "metadata": {},
   "source": [
    "#### Knockout shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "forty-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_type = ShiftType.Knockout\n",
    "shift_type_params = {\"cl\": MAJORITY}\n",
    "shift_str = \"ko_task2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accessible-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_result = main_experiment(model, method, X_valid, y_valid,\n",
    "                             c_valid, X_test_flatten, y_test, c_test,\n",
    "                             shift_type, ORIGINAL_SHAPE, n_classes,\n",
    "                             concept_names, concept_values, \n",
    "                             shift_type_params, n_exp=50, n_std=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "decimal-tongue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save file\n",
    "save_result(shift_str, method_str, dict_result, True, \"3dshapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-alloy",
   "metadata": {},
   "source": [
    "### CBSDh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "marked-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = DimensionalityReductor.CBSDh\n",
    "model = mt_model\n",
    "method_str = \"CBSDh\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-terrace",
   "metadata": {},
   "source": [
    "#### Knockout shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "academic-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_type = ShiftType.Knockout\n",
    "shift_type_params = {\"cl\": MAJORITY}\n",
    "shift_str = \"ko_task2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "built-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_result = main_experiment(model, method, X_valid, y_valid,\n",
    "                             c_valid, X_test_flatten, y_test, c_test,\n",
    "                             shift_type, ORIGINAL_SHAPE, n_classes,\n",
    "                             concept_names, concept_values, \n",
    "                             shift_type_params, n_exp=50, n_std=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "immediate-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file\n",
    "save_result(shift_str, method_str, dict_result, True, \"3dshapes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
