{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Utilities.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wxilELPCttj8",
        "jo6HxXCzlkbt",
        "W05G99vulp1o",
        "Hh9vt6Gnl8OV",
        "Mhq3Hokml_kR",
        "q2_KIKT-71K8"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD_AJcduttj0"
      },
      "source": [
        "# Utilities\n",
        "\n",
        "This notebook contains functions for applying, testing, and detecting shift. Additionally, it contains implementation of all neural network models, including end-to-end, concept bottleneck model (CBM), and concept model extraction (CME)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxilELPCttj8"
      },
      "source": [
        "## Loader Functions\n",
        "\n",
        "Contains functions to load data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK5yeyx_ttj8"
      },
      "source": [
        "def get_latent_sizes():\n",
        "    \"\"\"\n",
        "    Get the size of each concept (possible values of each class).\n",
        "    \"\"\"\n",
        "    \n",
        "    return np.array([1, 3, 6, 40, 32, 32])\n",
        "\n",
        "def get_latent_bases():\n",
        "    \"\"\"\n",
        "    Given vector (x, y, z) where each dimension is in base (a, b, c).\n",
        "    The following function will convert each of (x, y, z) dimensions to decimal.\n",
        "    \"\"\"\n",
        "    \n",
        "    latent_sizes = get_latent_sizes()\n",
        "    latent_bases = np.concatenate((latent_sizes[::-1].cumprod()[::-1][1:],\n",
        "                                np.array([1,])))\n",
        "    \n",
        "    return latent_bases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urXDNy4pttj9"
      },
      "source": [
        "def sample_latent(size=1):\n",
        "    \"\"\"\n",
        "    Used to randomly sample latent of size 'size'. Randomly sample data of size \n",
        "    'size'.\n",
        "\n",
        "    :param size: how many random samples\n",
        "    \n",
        "    :return: sample of 'size' latents\n",
        "    \"\"\"\n",
        "    \n",
        "    latents_sizes = get_latent_sizes()\n",
        "    samples = np.zeros((size, len(latents_sizes)))\n",
        "    for lat_i, lat_size in enumerate(latents_sizes):\n",
        "        samples[:, lat_i] = np.random.randint(lat_size, size=size)\n",
        "\n",
        "    return samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Gt3STottj-"
      },
      "source": [
        "def latent_to_index(latents):\n",
        "    \"\"\"\n",
        "    Convert from given latent to index position of it in the dataset.\n",
        "\n",
        "    :param latents: array of latent\n",
        "    \n",
        "    :return: list of indices\n",
        "    \"\"\"\n",
        "    \n",
        "    latents_bases = get_latent_bases()\n",
        "    return np.dot(latents, latents_bases).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahzztv50ttj_"
      },
      "source": [
        "def show_images_grid(imgs_, num_images=25):\n",
        "    \"\"\"\n",
        "    Used to visualise dSprite image in a grid.\n",
        "\n",
        "    :param imgs_: images to be drawn\n",
        "    :param num_images: number of images shown in the grid\n",
        "    \"\"\"\n",
        "    \n",
        "    ncols = int(np.ceil(num_images**0.5))\n",
        "    nrows = int(np.ceil(num_images / ncols))\n",
        "    _, axes = plt.subplots(ncols, nrows, figsize=(nrows * 2, ncols * 2))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    # Draw images on the given grid\n",
        "    for ax_i, ax in enumerate(axes):\n",
        "        if ax_i < num_images:\n",
        "            ax.imshow(imgs_[ax_i], cmap='Greys_r',  interpolation='nearest')\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "        else:\n",
        "            ax.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqdOEJMnttj_"
      },
      "source": [
        "def load_dsprites(path, dataset_size_used, train_size=0.85, class_index=1):\n",
        "    \"\"\"\n",
        "    Load dSprites dataset, split into train, validation, and test sets.\n",
        "\n",
        "    :param path: the path of the dataset\n",
        "    :param dataset_size_used: how many instances we will load into RAM\n",
        "    :param train_size: size of the training set\n",
        "    :param class_index: 1 for shape\n",
        "\n",
        "    :return\" x_train, x_test, y_train, y_test, c_train, c_test\n",
        "    \"\"\"\n",
        "\n",
        "    # Load dataset\n",
        "    dataset_zip = np.load(path)\n",
        "\n",
        "    # Extract relevant datas from the zip file\n",
        "    imgs = dataset_zip[\"imgs\"] # contains image data (737280 x 64 x 64)\n",
        "    latents_values = dataset_zip['latents_values'] # values of latent factors (or in this case concepts)\n",
        "    latents_classes = dataset_zip['latents_classes'] # classification targets (integer index of latents_values)\n",
        "\n",
        "    # Select data that will be used\n",
        "    indices_sampled = np.random.randint(0, imgs.shape[0], dataset_size_used)\n",
        "    X = np.expand_dims(imgs, axis=-1).astype(('float32'))\n",
        "    y = latents_classes[:, class_index] # shape for task 1\n",
        "    c = latents_classes # concepts\n",
        "    X = X[indices_sampled]\n",
        "    y = y[indices_sampled]\n",
        "    c = c[indices_sampled]\n",
        "\n",
        "    # Split X (image), y (shape for task 1), concepts to train test sets\n",
        "    x_train, x_test, y_train, y_test, c_train, c_test = train_test_split(X, y, c, train_size=train_size)\n",
        "    print('Training samples:', x_train.shape[0])\n",
        "    print('Testing samples:', x_test.shape[0])\n",
        "\n",
        "    return x_train, x_test, y_train, y_test, c_train, c_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE2XL1lHttkA"
      },
      "source": [
        "## Shifts Functions\n",
        "\n",
        "Contains various shift applicator, detections. The code here is adapted from https://github.com/steverab/failing-loudly, and modified by Maleakhi. Credit to the original authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJFOOhzattkB"
      },
      "source": [
        "### Shift Applicator\n",
        "\n",
        "Function to apply various types of shifts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvcDHF4BpVeS"
      },
      "source": [
        "def apply_gaussian_shift(X_te_orig, y_te_orig, shift_intensity, shift_prop):\n",
        "    \"\"\"\n",
        "    Given a dataset (in the experimentation, the test dataset), this function applies\n",
        "    Gaussian shift.\n",
        "    \n",
        "    :param X_te_orig: the X matrix (dataset features) where we will apply shifts.\n",
        "    :param y_te_orig: the y (label) where we will apply shifts.\n",
        "    :param shift: the shift name comprising shift intensity and proportion of data affected\n",
        "                 ({large/medium/small}_gn_shift_{0.1/0.5/1})\n",
        "\n",
        "    :return: shifted X and y\n",
        "    \"\"\"\n",
        "\n",
        "    X_te_1 = None\n",
        "    y_te_1 = None\n",
        "\n",
        "    # Gaussian noise shift on the features\n",
        "    if shift_intensity == \"large\":\n",
        "        noise_amt = 100.0\n",
        "    elif shift_intensity == \"medium\":\n",
        "        noise_amt = 10.0\n",
        "    else:\n",
        "        noise_amt = 1.0\n",
        "\n",
        "    normalization = 255.0\n",
        "    X_te_1, _ = gaussian_noise_subset(X_te_orig, noise_amt, normalization=normalization, delta_total=shift_prop)\n",
        "    y_te_1 = y_te_orig.copy()\n",
        "    \n",
        "    return (X_te_1, y_te_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAc0uHIVq4HB"
      },
      "source": [
        "def apply_ko_shift(X_te_orig, y_te_orig, shift_intensity, cl=0):\n",
        "    \"\"\"\n",
        "    Given a dataset (in the experimentation, the test dataset), this function applies\n",
        "    the knockout shift, removing subsets of data.\n",
        "    \n",
        "    :param X_te_orig: the X matrix (dataset features) where we will apply shifts.\n",
        "    :param y_te_orig: the y (label) where we will apply shifts.\n",
        "    :param shift_intensity: the shift name comprising shift proportion of data affected\n",
        "                 ko_shift_(0.1/0.5/1.0)\n",
        "    :param cl: indicate class that will be removed (making general imbalance in the dataset)\n",
        "\n",
        "    :return: shifted X and y\n",
        "    \"\"\"\n",
        "\n",
        "    X_te_1 = None\n",
        "    y_te_1 = None\n",
        "\n",
        "    # Knockout shift, creating class imbalance on the dataset\n",
        "    if shift_intensity == \"large\":\n",
        "        prop = 1.0\n",
        "    elif shift_intensity == \"medium\":\n",
        "        prop = 0.5\n",
        "    else:\n",
        "        prop = 0.1\n",
        "    \n",
        "    X_te_1, y_te_1 = knockout_shift(X_te_orig, y_te_orig, cl, prop)\n",
        "\n",
        "    return (X_te_1, y_te_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yyuo7LjAr6dB"
      },
      "source": [
        "def apply_img_shift(X_te_orig, y_te_orig, orig_dims, shift_intensity, shift_prop, shift_types=[]):\n",
        "    \"\"\"\n",
        "    Given a dataset (in the experimentation, the test dataset), this function applies\n",
        "    the knockout shift, removing subsets of data.\n",
        "    \n",
        "    :param X_te_orig: the X matrix (dataset features) where we will apply shifts.\n",
        "    :param y_te_orig: the y (label) where we will apply shifts.\n",
        "    :param orig_dims: original dimensions of the image (img.shape[1:] - width, height, channel)\n",
        "    :param shift_intensity: \"small\", \"medium\", \"large\"\n",
        "    :param shift_proportion: proportion of the data shifted, default value = 0.1, 0.5, 1.0\n",
        "    :param shift_types: list indicating shifts that we want to apply. If given [], apply all shifts randomly.\n",
        "        Possible shift types includes:\n",
        "        - 'width_shift'\n",
        "        - 'height_shift'\n",
        "        - 'rotation'\n",
        "        - 'shear'\n",
        "        - 'zoom'\n",
        "        - 'flip'\n",
        "    \n",
        "    :return: shifted X and y\n",
        "    \"\"\"\n",
        "\n",
        "    X_te_1 = None\n",
        "    y_te_1 = None\n",
        "\n",
        "    # Get default configuration\n",
        "    config = image_data_generator_config()\n",
        "\n",
        "    ## No specific type of image shifts given\n",
        "    if not shift_types:\n",
        "        rotation_range = config[\"rotation_range\"][shift_intensity]\n",
        "        width_shift_range = config[\"width_shift_range\"][shift_intensity]\n",
        "        height_shift_range = config[\"height_shift_range\"][shift_intensity]\n",
        "        shear_range = config[\"shear_range\"][shift_intensity]\n",
        "        zoom_range = config[\"zoom_range\"][shift_intensity]\n",
        "        horizontal_flip = config[\"flip_range\"][shift_intensity][0]\n",
        "        vertical_flip = config[\"flip_range\"][shift_intensity][1]\n",
        "    \n",
        "    ## Else, select parameters accordingly\n",
        "    else:\n",
        "        all_shifts = [\"width_shift\", \"height_shift\", \"rotation\", \"shear\", \"zoom\", \"flip\"]\n",
        "\n",
        "        for shift_type in shift_types:\n",
        "            if shift_type == \"width_shift\":\n",
        "                width_shift_range = config[\"width_shift_range\"][shift_intensity]\n",
        "            if shift_type == \"height_shift\":\n",
        "                height_shift_range = config[\"height_shift_range\"][shift_intensity]\n",
        "            if shift_type == \"rotation\":\n",
        "                rotation_range = config[\"rotation_range\"][shift_intensity]\n",
        "            if shift_type == \"shear\":\n",
        "                shear_range = config[\"shear_range\"][shift_intensity]\n",
        "            if shift_type == \"zoom\":\n",
        "                zoom_range = config[\"zoom_range\"][shift_intensity]\n",
        "            if shift_type == \"flip\":\n",
        "                horizontal_flip = config[\"flip_range\"][shift_intensity][0]\n",
        "                vertical_flip = config[\"flip_range\"][shift_intensity][1]\n",
        "            \n",
        "            all_shifts.remove(shift_type)\n",
        "        \n",
        "        # For non-included, use default value\n",
        "        for shift_type in all_shifts:\n",
        "            if shift_type == \"width_shift\":\n",
        "                width_shift_range = config[\"width_shift_range\"][\"default\"]\n",
        "            if shift_type == \"height_shift\":\n",
        "                height_shift_range = config[\"height_shift_range\"][\"default\"]\n",
        "            if shift_type == \"rotation\":\n",
        "                rotation_range = config[\"rotation_range\"][\"default\"]\n",
        "            if shift_type == \"shear\":\n",
        "                shear_range = config[\"shear_range\"][\"default\"]\n",
        "            if shift_type == \"zoom\":\n",
        "                zoom_range = config[\"zoom_range\"][\"default\"]\n",
        "            if shift_type == \"flip\":\n",
        "                horizontal_flip = config[\"flip_range\"][\"default\"][0]\n",
        "                vertical_flip = config[\"flip_range\"][\"default\"][1]\n",
        "\n",
        "    ## Apply shift using the parameters\n",
        "    X_te_1, _ = image_generator(X_te_orig, \n",
        "                                orig_dims, \n",
        "                                rotation_range, \n",
        "                                width_shift_range,\n",
        "                                height_shift_range, \n",
        "                                shear_range, \n",
        "                                zoom_range, \n",
        "                                horizontal_flip, \n",
        "                                vertical_flip, \n",
        "                                delta=shift_prop)\n",
        "    y_te_1 = y_te_orig.copy()\n",
        "    \n",
        "    return (X_te_1, y_te_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEnXXoBayBqI"
      },
      "source": [
        "### Shift Tester\n",
        "\n",
        "Contains functions related to statistical tests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ65oyOYyEYg"
      },
      "source": [
        "def test_shift_bin(n_successes, n, p):\n",
        "    \"\"\"\n",
        "    Binomial test for domain classifier. Used to check whether accuracy is statistically\n",
        "    significant.\n",
        "\n",
        "    :param n_successes: number of correctly predicted instances\n",
        "    :param n: number of predictions made (test instances)\n",
        "    :param p: hypothesised probability of success\n",
        "\n",
        "    :return: pvalue\n",
        "    \"\"\"\n",
        "    p_val = binom_test(n_successes, n, p)\n",
        "    return p_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYKD8gGFBu-W"
      },
      "source": [
        "    def one_dimensional_test(X1, X2, test_type=\"KS\"):\n",
        "        \"\"\"\n",
        "        Given two matrices (each matrix is of size n x feature), we conduct one \n",
        "        dimensional statistical test to each of the component using Kolmogorov-Smirnov\n",
        "        or Anderson Darling to check whether each component comes from the same distribution.\n",
        "\n",
        "        :param X1: matrix of data1 of size n x number of features\n",
        "        :param X2: matrix of data2 of size n x number of features\n",
        "        :param test_type: specify the one dimensional test to compare distributions\n",
        "            of components (can be KS || AD)\n",
        "\n",
        "        :return: minimum p values from all individual test, where we will check if\n",
        "            its value less than alpha / number of components\n",
        "        \"\"\"\n",
        "        p_vals = []\n",
        "        t_vals = []\n",
        "\n",
        "        # For each dimension we conduct a separate statistical test\n",
        "        # Iterate over components\n",
        "        ## Note: need to modify range, weird behaviour python\n",
        "        for i in range(X1.shape[1]):\n",
        "            feature_X1 = X1[:, i]\n",
        "            feature_X2 = X2[:, i]\n",
        "\n",
        "            t_val, p_val = None, None\n",
        "\n",
        "            if test_type == \"KS\":\n",
        "                # Compute KS statistic and p-value\n",
        "                t_val, p_val = ks_2samp(feature_X1, feature_X2)\n",
        "            else:\n",
        "                t_val, _, p_val = anderson_ksamp([feature_X1.tolist(), feature_X2.tolist()])\n",
        "\n",
        "            p_vals.append(p_val)\n",
        "            t_vals.append(t_val)\n",
        "\n",
        "        # Apply the Bonferroni correction to bound the family-wise error rate. This can be done by picking the minimum\n",
        "        # p-value from all individual tests.\n",
        "        p_vals = np.array(p_vals)\n",
        "        p_val = np.min(p_vals)\n",
        "\n",
        "        return p_val, p_vals, t_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j78m0iJ0EglH"
      },
      "source": [
        "def test_chi2_shift(X1, X2, nb_classes):\n",
        "    \"\"\"\n",
        "    Used for testing BBSD with hard threshold. Theoretically we conduct categorical\n",
        "    chi2 test to test whether the distribution of the class follow theoretical\n",
        "    chi2 distributions.\n",
        "\n",
        "    :param X1: matrix of data1 of size n x number of features\n",
        "    :param X2: matrix of data2 of size n x number of features\n",
        "    :param nb_classes: number of classes (for degree of freedom)\n",
        "\n",
        "    :return: p-value\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate observed and expected counts\n",
        "    freq_exp = np.zeros(nb_classes)\n",
        "    freq_obs = np.zeros(nb_classes)\n",
        "\n",
        "    unique_X1, counts_X1 = np.unique(X1, return_counts=True)\n",
        "    total_counts_X1 = np.sum(counts_X1)\n",
        "    unique_X2, counts_X2 = np.unique(X2, return_counts=True)\n",
        "    total_counts_X2 = np.sum(counts_X2)\n",
        "\n",
        "    for i in range(len(unique_X1)):\n",
        "        freq_exp[unique_X1[i]] = counts_X1[i]\n",
        "        \n",
        "    for i in range(0, len(unique_X2)):\n",
        "        i = int(i)\n",
        "        freq_obs[unique_X2[i]] = counts_X2[i]\n",
        "\n",
        "    if np.amin(freq_exp) == 0 or np.amin(freq_obs) == 0:\n",
        "        # The chi-squared test using contingency tables is not well defined if zero-element classes exist, which\n",
        "        # might happen in the low-sample regime. In this case, we calculate the standard chi-squared test.\n",
        "        for i in range(0, len(unique_X1)):\n",
        "            i = int(i)\n",
        "            val = counts_X1[i] / total_counts_X1 * total_counts_X2\n",
        "            freq_exp[unique_X1[i]] = val\n",
        "        chi2, p_val = chisquare(freq_obs, f_exp=freq_exp)\n",
        "    else:\n",
        "        # In almost all cases, we resort to obtaining a p-value from the chi-squared test's contingency table.\n",
        "        freq_conc = np.array([freq_exp, freq_obs])\n",
        "        chi2, p_val, _, _ = chi2_contingency(freq_conc)\n",
        "    \n",
        "    return chi2, p_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRORBuupGTnw"
      },
      "source": [
        "def multi_dimensional_test(X1, X2):\n",
        "    \"\"\"\n",
        "    Perform MMD multi dimensional test. See paper for more details.\n",
        "\n",
        "    :param X1: matrix of data1 of size n x number of features\n",
        "    :param X2: matrix of data2 of size n x number of features\n",
        "\n",
        "    :return: p-value\n",
        "    \"\"\"\n",
        "\n",
        "    # torch_two_sample somehow wants the inputs to be explicitly casted to float 32.\n",
        "    X1 = X1.astype(np.float32)\n",
        "    X2 = X2.astype(np.float32)\n",
        "\n",
        "    p_val = None\n",
        "\n",
        "    # Do the MMD test\n",
        "    mmd_test = MMDStatistic(len(X1), len(X2))\n",
        "\n",
        "    # As per the original MMD paper, the median distance between all points in the aggregate sample from both\n",
        "    # distributions is a good heuristic for the kernel bandwidth, which is why compute this distance here.\n",
        "    if len(X1.shape) == 1:\n",
        "        X1 = X1.reshape((len(X1),1))\n",
        "        X2 = X2.reshape((len(X2),1))\n",
        "        all_dist = distance.cdist(X1, X2, 'euclidean')\n",
        "    else:\n",
        "        all_dist = distance.cdist(X1, X2, 'euclidean')\n",
        "    median_dist = np.median(all_dist)\n",
        "\n",
        "    # Calculate MMD.\n",
        "    t_val, matrix = mmd_test(torch.autograd.Variable(torch.tensor(X1)),\n",
        "                                torch.autograd.Variable(torch.tensor(X2)),\n",
        "                                alphas=[1/median_dist], ret_matrix=True)\n",
        "    p_val = mmd_test.pval(matrix)\n",
        "        \n",
        "    return p_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAvM7Q_6Py6r"
      },
      "source": [
        "## Dimensionality Reduction Functions\n",
        "\n",
        "Contain functions implementing various dimensionality reduction methods that we apply in the experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo6HxXCzlkbt"
      },
      "source": [
        "### Standard Dimensionality Reduction Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLGFIo_AP8mz"
      },
      "source": [
        "def principal_components_anaylsis(X, n_components=None):\n",
        "    \"\"\"\n",
        "    Apply principal components to data (fit).\n",
        "\n",
        "    :param X: datasets to be fitted (matrix)\n",
        "    :param n_components: number of components PCA\n",
        "    \"\"\"\n",
        "\n",
        "    # If number of components is not specified, calculate first\n",
        "    if n_components is None:\n",
        "        # Explain 80% variance of the original data\n",
        "        pca = PCA(n_components=.8, svd_solver=\"full\")\n",
        "        pca.fit(X)\n",
        "        n_components = pca.n_components_ \n",
        "    \n",
        "    pca = PCA(n_components=n_components)\n",
        "    pca.fit(X)\n",
        "    \n",
        "    return pca"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpD0vj9pP8pG"
      },
      "source": [
        "def sparse_random_projection(X, n_components=None):\n",
        "    \"\"\"\n",
        "    Apply SRP to data (fit).\n",
        "\n",
        "    :param X: datasets to be fitted (matrix)\n",
        "    :param n_components: number of components PCA\n",
        "    \"\"\"\n",
        "\n",
        "    # If number of components is not specified, calculate first\n",
        "    if n_components is None:\n",
        "        # Explain 80% variance of the original data\n",
        "        pca = PCA(n_components=.8, svd_solver=\"full\")\n",
        "        pca.fit(X)\n",
        "        n_components = pca.n_components_ \n",
        "    \n",
        "    srp = SparseRandomProjection(n_components=n_components)\n",
        "    srp.fit(X)\n",
        "    return srp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W05G99vulp1o"
      },
      "source": [
        "### BBSD Models\n",
        "\n",
        "Blackbox shift detection models are the original models for the original task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh9vt6Gnl8OV"
      },
      "source": [
        "#### End to End Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBxWB-4bl_0r"
      },
      "source": [
        "## Shared layers block class\n",
        "class CNNBlock(layers.Layer):\n",
        "    \"\"\"\n",
        "    Shared layers for the input-to-concept models and end-to-end.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNNBlock, self).__init__()\n",
        "\n",
        "        # Shared layers component\n",
        "        self.conv1 = layers.Conv2D(64, (8, 8), strides=(2, 2), padding='same')\n",
        "        self.do1 = layers.Dropout(0.3)\n",
        "\n",
        "        self.conv2 = layers.Conv2D(128, (6, 6), strides=(2, 2), padding='valid')\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "\n",
        "        self.conv3 = layers.Conv2D(128, (5, 5), strides=(1, 1), padding='valid')\n",
        "        self.pool1 = layers.MaxPooling2D((2, 2))\n",
        "        self.do2 = layers.Dropout(0.3)\n",
        "\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.dense1 = layers.Dense(128, activation=\"relu\")\n",
        "        self.do3 = layers.Dropout(0.4)\n",
        "        self.dense2 = layers.Dense(64, activation=\"relu\")\n",
        "        self.do4 = layers.Dropout(0.2)\n",
        "    \n",
        "    def call(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = self.do1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.do2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.do3(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.do4(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bVpr6hKlHJD"
      },
      "source": [
        "def NeuralNetworkClassifier(num_classes):\n",
        "    \"\"\"\n",
        "    Build and return end-to-end model.\n",
        "\n",
        "    :param num_classes: number of classes.\n",
        "\n",
        "    :return: model architecture\n",
        "    \"\"\"\n",
        "\n",
        "    img_inputs = tf.keras.Input(shape=(64, 64, 1))\n",
        "\n",
        "    # Shared layers\n",
        "    x = CNNBlock()(img_inputs)\n",
        "\n",
        "    # prediction using softmax (shape has three)\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    # Return model\n",
        "    model = tf.keras.Model(inputs=img_inputs, outputs=out)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhq3Hokml_kR"
      },
      "source": [
        "#### Concept Bottleneck Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2tONNKXl_3L"
      },
      "source": [
        "## Input to Concept Model\n",
        "def MultitaskModel():\n",
        "    \"\"\"\n",
        "    Build and return multi-task model.\n",
        "    \"\"\"\n",
        "        \n",
        "    img_inputs = tf.keras.Input(shape=(64, 64, 1))\n",
        "    \n",
        "    # Shared layers\n",
        "    x = CNNBlock()(img_inputs)\n",
        "    \n",
        "    # Task specific layer\n",
        "    task_color = layers.Dense(1, activation=\"softmax\", name=\"color\")(x)\n",
        "    task_shape = layers.Dense(3, activation=\"softmax\", name=\"shape\")(x)\n",
        "    task_scale = layers.Dense(6, activation=\"softmax\", name=\"scale\")(x)\n",
        "    task_rotation = layers.Dense(40, activation=\"softmax\", name=\"rotation\")(x)\n",
        "    task_x = layers.Dense(32, activation=\"softmax\", name=\"x\")(x)\n",
        "    task_y = layers.Dense(32, activation=\"softmax\", name=\"y\")(x)\n",
        "    \n",
        "    # Return model\n",
        "    model = tf.keras.Model(inputs=img_inputs, outputs=[task_color, task_shape, task_scale, task_rotation, task_x, task_y])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txXxqFLCC3Df"
      },
      "source": [
        "## Input to Concept Model\n",
        "def IndividualModel(num_classes, name):\n",
        "    \"\"\"\n",
        "    Build an individual model for a particular task.\n",
        "\n",
        "    :param num_classes: number of possible values for a particular task.\n",
        "    :param name: name of the task\n",
        "\n",
        "    :return: model architecture\n",
        "    \"\"\"\n",
        "        \n",
        "    img_inputs = tf.keras.Input(shape=(64, 64, 1))\n",
        "    \n",
        "    # Shared layers\n",
        "    x = CNNBlock()(img_inputs)\n",
        "    \n",
        "    # Task specific layer\n",
        "    output = layers.Dense(num_classes, activation=\"softmax\", name=name)(x)\n",
        "\n",
        "    # Return model\n",
        "    model = tf.keras.Model(inputs=img_inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "def EnsembleModel():\n",
        "    \"\"\"\n",
        "    Stack individual model, one for each task.\n",
        "\n",
        "    :return: list of models\n",
        "    \"\"\"\n",
        "\n",
        "    model_color = IndividualModel(num_classes=1, name=\"color\")\n",
        "    model_shape = IndividualModel(num_classes=3, name=\"shape\")\n",
        "    model_scale = IndividualModel(num_classes=6, name=\"scale\")\n",
        "    model_rotation = IndividualModel(num_classes=40, name=\"rotation\")\n",
        "    model_x = IndividualModel(num_classes=32, name=\"x\")\n",
        "    model_y = IndividualModel(num_classes=32, name=\"y\")\n",
        "\n",
        "    models = [model_color, model_shape, model_scale, model_rotation, model_x, model_y]\n",
        "\n",
        "    return models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQWDuRsSl_5L"
      },
      "source": [
        "## Input to Concept Model\n",
        "def BinaryModel():\n",
        "    \"\"\"\n",
        "    Build binary model for the task.\n",
        "\n",
        "    :param num_classes: number of possible values for a particular task.\n",
        "    :param name: name of the task\n",
        "\n",
        "    :return: model architecture\n",
        "    \"\"\"\n",
        "        \n",
        "    img_inputs = tf.keras.Input(shape=(64, 64, 1))\n",
        "    \n",
        "    # Shared layers\n",
        "    x = CNNBlock()(img_inputs)\n",
        "    \n",
        "    # Task specific layer\n",
        "    output = layers.Dense(1+3+6+40+32+32, activation=\"sigmoid\")(x)\n",
        "\n",
        "    # Return model\n",
        "    model = tf.keras.Model(inputs=img_inputs, outputs=output)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2_KIKT-71K8"
      },
      "source": [
        "## Domain Classifier Functions\n",
        "\n",
        "Contains related domain classifier functions, including data generation, model builder, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbWKTNT97-td"
      },
      "source": [
        "def generate_domain_classifier_data(x_clean, y_clean, x_altered, y_altered, delta=0.5):\n",
        "    \"\"\"\n",
        "    Given two sets of data (x_clean, y_clean) and (x_altered, y_altered), we merge\n",
        "    them to create a new dataset that will be the input for the domain classifier.\n",
        "\n",
        "    :param x_clean: the clean (training) data feature\n",
        "    :param y_clean: the clean (training) data label\n",
        "    :param x_altered: the o.o.d/ shifted/ real world (test) data feature\n",
        "    :param y_altered the o.o.d/ shifted/ real world (test) data label\n",
        "    :param delta: new training and testing proportion\n",
        "\n",
        "    :return: x_train_new, y_train_new, y_train_old, x_test_new, y_test_new, y_test_old\n",
        "       where y_train_new is label 0 if comes from clean and 1 if comes from altered\n",
        "    \"\"\"\n",
        "\n",
        "    ## Clean\n",
        "    # Get indices\n",
        "    training_indices = np.random.choice(x_clean.shape[0], ceil(x_clean.shape[0] * delta), replace=False)    \n",
        "    test_indices = [i for i in range(x_clean.shape[0]) if i not in training_indices]\n",
        "\n",
        "    # Extract datasets\n",
        "    x_clean_train = x_clean[training_indices, :]\n",
        "    x_clean_test = x_clean[test_indices, :]\n",
        "    y_clean_train = y_clean[training_indices]\n",
        "    y_clean_test = y_clean[test_indices]\n",
        "\n",
        "    ## Altered\n",
        "    x_altered_train = x_altered[training_indices, :]\n",
        "    x_altered_test = x_altered[test_indices, :]\n",
        "    y_altered_train = y_altered[training_indices]\n",
        "    y_altered_test = y_altered[test_indices]\n",
        "\n",
        "    ## Recombine datasets\n",
        "    x_train_new = np.append(x_clean_train, x_altered_train, axis=0)\n",
        "    y_train_old = np.append(y_clean_train, y_altered_train)\n",
        "    y_train_new = np.zeros(len(x_train_new))\n",
        "    y_train_new[len(x_clean_train):] = np.ones(len(x_altered_train))\n",
        "\n",
        "    x_test_new = np.append(x_clean_test, x_altered_test, axis=0)\n",
        "    y_test_old = np.append(y_clean_test, y_altered_test)\n",
        "    y_test_new = np.zeros(len(x_test_new))\n",
        "    y_test_new[len(x_clean_test):] = np.ones(len(x_altered_test))\n",
        "\n",
        "    ## Shuffle them\n",
        "    x_train_new, y_train_new, y_train_old = unison_shuffled_copies(x_train_new, y_train_new, y_train_old)\n",
        "    x_test_new, y_test_new, y_test_old = unison_shuffled_copies(x_test_new, y_test_new, y_test_old)\n",
        "\n",
        "    return x_train_new, y_train_new, y_train_old, x_test_new, y_test_new, y_test_old"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD95iCBwttkJ"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "Contains functionalities helping the other functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81DtsuVzttkP"
      },
      "source": [
        "def gaussian_noise_subset(x, noise_amt, normalization=1.0, delta_total=1.0, clip=True):\n",
        "    \"\"\"\n",
        "    Apply gaussian noise to x.\n",
        "    \n",
        "    :param noise_amt: the amount of gaussian noise applied.\n",
        "    :param normalization: max range of the value, for pixel it would be 255 (represent color)\n",
        "    :param delta_total: proportion of data which we randomly applied noise\n",
        "    :param clip: whether to clip the new result between 0 and 1.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Indices of images where we apply noise (random indices)\n",
        "    indices = np.random.choice(x.shape[0], ceil(x.shape[0] * delta_total), replace=False)\n",
        "    x_mod = x[indices, :] # images\n",
        "    \n",
        "    # Create noise of appropriate size for all pixels (or other data structures)\n",
        "    noise = np.random.normal(0, noise_amt / normalization, (x_mod.shape[0], x_mod.shape[1]))\n",
        "    \n",
        "    # Clip X\n",
        "    if clip:\n",
        "        x_mod = np.clip(x_mod + noise, 0., 1.)\n",
        "    else:\n",
        "        x_mod = x_mod + noise\n",
        "    \n",
        "    # Return noisy X\n",
        "    x[indices, :] = x_mod\n",
        "    return x, indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZplgyvhttkQ"
      },
      "source": [
        "def knockout_shift(x, y, cl, delta):\n",
        "    \"\"\"\n",
        "    The knockout shift remove instances from a class in order to create class imbalance.\n",
        "    \n",
        "    :param x: the feature matrix\n",
        "    :param y: the label array\n",
        "    :param cl: the class label where we will remove its instances to create imbalance\n",
        "    :param delta: proportion of data to be shifted.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Indices to be deleted\n",
        "    del_indices = np.where(y == cl)[0]\n",
        "    until_index = ceil(delta * len(del_indices))\n",
        "    \n",
        "    if until_index % 2 != 0:\n",
        "        until_index = until_index + 1\n",
        "    \n",
        "    del_indices = del_indices[:until_index]\n",
        "    \n",
        "    # Delete instances of del_indices\n",
        "    x = np.delete(x, del_indices, axis=0)\n",
        "    y = np.delete(y, del_indices, axis=0)\n",
        "    \n",
        "    # Return reduced data\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0lOmxNNttkQ"
      },
      "source": [
        "def image_generator(x, \n",
        "                    orig_dims, \n",
        "                    rot_range, \n",
        "                    width_range, \n",
        "                    height_range, \n",
        "                    shear_range, \n",
        "                    zoom_range, \n",
        "                    horizontal_flip, \n",
        "                    vertical_flip, \n",
        "                    delta=1.0):\n",
        "    \"\"\"\n",
        "    Perform image perturbations (e.g., translation, rotation, shear, zoom).\n",
        "    \n",
        "    :param x: the image.\n",
        "    :param orig_dims: original dimension of the input image (not including batch size: height, width, channel only).\n",
        "    :param rot_range, width_range, height_range, shear_range, zoom_range, horizontal_flip, vertical_flip:\n",
        "        range of augmentation values (for flip - boolean indicating whether to do horizontal and vertical flip)\n",
        "    :param delta: proportion of data where we will apply the shift.\n",
        "    \n",
        "    :return: new images, and indices where we apply the image perturbations.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Random indices where we will apply shift transformation\n",
        "    indices = np.random.choice(x.shape[0], ceil(x.shape[0] * delta), replace=False)\n",
        "    datagen = ImageDataGenerator(rotation_range=rot_range,\n",
        "                                 width_shift_range=width_range,\n",
        "                                 height_shift_range=height_range,\n",
        "                                 shear_range=shear_range,\n",
        "                                 zoom_range=zoom_range,\n",
        "                                 horizontal_flip=horizontal_flip,\n",
        "                                 vertical_flip=vertical_flip,\n",
        "                                 fill_mode=\"constant\")\n",
        "    \n",
        "    # Subset of images with random indices\n",
        "    x_mod = x[indices, :]\n",
        "    for idx in range(len(x_mod)):\n",
        "        img_sample = x_mod[idx, :].reshape(orig_dims) # reshape single image to original image\n",
        "        mod_img_sample = datagen.flow(np.array([img_sample]), batch_size=1)[0]\n",
        "        x_mod[idx, :] = mod_img_sample.reshape(np.prod(mod_img_sample.shape))\n",
        "    x[indices, :] = x_mod\n",
        "    \n",
        "    return x, indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZr8B6XCTRwZ"
      },
      "source": [
        "def unison_shuffled_copies(a, b, c):\n",
        "    \"\"\"\n",
        "    Used to shuffle a, b, c together.\n",
        "\n",
        "    :param a, b, c: arrays of same length.\n",
        "\n",
        "    :return: shuffled a, b, c\n",
        "    \"\"\"\n",
        "\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p], c[p]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiYHNNKb9Beg"
      },
      "source": [
        "def image_data_generator_config():\n",
        "    \"\"\"\n",
        "    Encapsulate image data generator configuration.\n",
        "\n",
        "    :return: dictionary containing the configuration.\n",
        "    \"\"\"\n",
        "\n",
        "    # Rotation\n",
        "    rotation_range = {\n",
        "        \"default\": 0,\n",
        "        \"small\": 10,\n",
        "        \"medium\": 40,\n",
        "        \"large\": 90\n",
        "    }\n",
        "\n",
        "    # Width shift (x-translation)\n",
        "    width_shift_range = {\n",
        "        \"default\": 0.0,\n",
        "        \"small\": 0.05,\n",
        "        \"medium\": 0.2,\n",
        "        \"large\": 0.4\n",
        "    }\n",
        "\n",
        "    # Height shift (y-translation)\n",
        "    height_shift_range = {\n",
        "        \"default\": 0.0,\n",
        "        \"small\": 0.05,\n",
        "        \"medium\": 0.2,\n",
        "        \"large\": 0.4\n",
        "    }\n",
        "\n",
        "    # Shear\n",
        "    shear_range = {\n",
        "        \"default\": 0.0,\n",
        "        \"small\": 0.1,\n",
        "        \"medium\": 0.2,\n",
        "        \"large\": 0.3\n",
        "    }\n",
        "\n",
        "    # Zoom\n",
        "    zoom_range = {\n",
        "        \"default\": 0.0,\n",
        "        \"small\": 0.1,\n",
        "        \"medium\": 0.2,\n",
        "        \"large\": 0.4\n",
        "    }\n",
        "\n",
        "    # Flip\n",
        "    flip = {\n",
        "        \"default\": (False, False),\n",
        "        \"small\": (False, False),\n",
        "        \"medium\": (True, False),\n",
        "        \"large\": (True, True)\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"rotation_range\": rotation_range,\n",
        "        \"width_shift_range\": width_shift_range,\n",
        "        \"height_shift_range\": height_shift_range,\n",
        "        \"shear_range\": shear_range,\n",
        "        \"zoom_range\": zoom_range,\n",
        "        \"flip_range\": flip\n",
        "    }\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}